{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-12T11:17:16.134706Z","iopub.execute_input":"2022-05-12T11:17:16.135048Z","iopub.status.idle":"2022-05-12T11:17:16.309857Z","shell.execute_reply.started":"2022-05-12T11:17:16.134965Z","shell.execute_reply":"2022-05-12T11:17:16.309071Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/preprocessed-data/dev.csv\n/kaggle/input/preprocessed-data/covid_2.csv\n/kaggle/input/preprocessed-data/covid.csv\n/kaggle/input/preprocessed-data/best_weights.pt\n/kaggle/input/preprocessed-data/train.csv\n/kaggle/input/preprocessed-data/test.csv\n/kaggle/input/preprocessed-data/covid_1.csv\n/kaggle/input/experimental/dev.csv\n/kaggle/input/experimental/train.csv\n/kaggle/input/test-event-file/668849913678209024.json\n/kaggle/input/test-event-file/519348106836860929.json\n/kaggle/input/test-event-file/1234328552729792512.json\n/kaggle/input/test-event-file/1251176149591511040.json\n/kaggle/input/test-event-file/544358564484378624.json\n/kaggle/input/test-event-file/1238293201108094976.json\n/kaggle/input/test-event-file/1260009210831491073.json\n/kaggle/input/test-event-file/1246368667169783808.json\n/kaggle/input/test-event-file/519112613800972288.json\n/kaggle/input/test-event-file/1272307234001821697.json\n/kaggle/input/test-event-file/1278345269751492611.json\n/kaggle/input/test-event-file/1257445088298512386.json\n/kaggle/input/test-event-file/1250379310201999360.json\n/kaggle/input/test-event-file/509464271118688257.json\n/kaggle/input/test-event-file/1248525224938618882.json\n/kaggle/input/test-event-file/1256276448995770368.json\n/kaggle/input/test-event-file/1247863014080028673.json\n/kaggle/input/test-event-file/524923676484177920.json\n/kaggle/input/test-event-file/1249664310877376513.json\n/kaggle/input/test-event-file/489796998615547904.json\n/kaggle/input/test-event-file/1276834267864150017.json\n/kaggle/input/test-event-file/387031585834278912.json\n/kaggle/input/test-event-file/504433135036407808.json\n/kaggle/input/test-event-file/1249234760297148418.json\n/kaggle/input/test-event-file/1251668952993927170.json\n/kaggle/input/test-event-file/1278470852540055552.json\n/kaggle/input/test-event-file/1240497782097620992.json\n/kaggle/input/test-event-file/1240171759724154881.json\n/kaggle/input/test-event-file/1248762939261116421.json\n/kaggle/input/test-event-file/1244323325729439746.json\n/kaggle/input/test-event-file/1223278788089470977.json\n/kaggle/input/test-event-file/1270632467213549568.json\n/kaggle/input/test-event-file/1263649035912650752.json\n/kaggle/input/test-event-file/1245797723611201538.json\n/kaggle/input/test-event-file/1247072275331002369.json\n/kaggle/input/test-event-file/491241885399539712.json\n/kaggle/input/test-event-file/530943279161155584.json\n/kaggle/input/test-event-file/1254125580351569921.json\n/kaggle/input/test-event-file/514535408126795776.json\n/kaggle/input/test-event-file/1248087887473602560.json\n/kaggle/input/test-event-file/1275994059534766086.json\n/kaggle/input/test-event-file/1241047449348632577.json\n/kaggle/input/test-event-file/1235238338711478273.json\n/kaggle/input/test-event-file/1259739644981215235.json\n/kaggle/input/test-event-file/551120768164462592.json\n/kaggle/input/test-event-file/1273236678505889800.json\n/kaggle/input/test-event-file/547101266313089024.json\n/kaggle/input/test-event-file/1240570885662289920.json\n/kaggle/input/test-event-file/1240398845491765248.json\n/kaggle/input/test-event-file/525039784503541760.json\n/kaggle/input/test-event-file/1223590209486573568.json\n/kaggle/input/test-event-file/1252260737021546496.json\n/kaggle/input/test-event-file/1249728188286197763.json\n/kaggle/input/test-event-file/1251054683692597248.json\n/kaggle/input/test-event-file/1237323520142696449.json\n/kaggle/input/test-event-file/407193347279699968.json\n/kaggle/input/test-event-file/1250100846144057348.json\n/kaggle/input/test-event-file/1224642863419416578.json\n/kaggle/input/test-event-file/521789009576476673.json\n/kaggle/input/test-event-file/515598200796090369.json\n/kaggle/input/test-event-file/1252188225684344832.json\n/kaggle/input/test-event-file/514508854990999553.json\n/kaggle/input/test-event-file/623599854661541888.json\n/kaggle/input/test-event-file/1274140194086817793.json\n/kaggle/input/test-event-file/495365942726381568.json\n/kaggle/input/test-event-file/1234019691498295297.json\n/kaggle/input/test-event-file/551099691702956032.json\n/kaggle/input/test-event-file/1234884616479051777.json\n/kaggle/input/test-event-file/572002458647412736.json\n/kaggle/input/test-event-file/1246830448254181385.json\n/kaggle/input/test-event-file/544457299667202048.json\n/kaggle/input/test-event-file/532276693931945984.json\n/kaggle/input/test-event-file/513922322915282945.json\n/kaggle/input/test-event-file/357299879070023680.json\n/kaggle/input/test-event-file/531607884220485632.json\n/kaggle/input/test-event-file/1248490841053605888.json\n/kaggle/input/test-event-file/523535962962280448.json\n/kaggle/input/test-event-file/669201837187334144.json\n/kaggle/input/test-event-file/1274828323508621312.json\n/kaggle/input/test-event-file/568075025418317826.json\n/kaggle/input/test-event-file/1240724896457601026.json\n/kaggle/input/test-event-file/1264926045276422144.json\n/kaggle/input/test-event-file/1247218202796535809.json\n/kaggle/input/test-event-file/524952094986350592.json\n/kaggle/input/test-event-file/665575674485211136.json\n/kaggle/input/test-event-file/1235582115900796928.json\n/kaggle/input/test-event-file/535315394127728641.json\n/kaggle/input/test-event-file/491591245152935936.json\n/kaggle/input/test-event-file/1255268594709073921.json\n/kaggle/input/test-event-file/1242669446478671872.json\n/kaggle/input/test-event-file/1240167195193139200.json\n/kaggle/input/test-event-file/1241596183874863105.json\n/kaggle/input/test-event-file/1252145401806966787.json\n/kaggle/input/test-event-file/1246848873513005057.json\n/kaggle/input/test-event-file/1258349086597615616.json\n/kaggle/input/test-event-file/615494435074363392.json\n/kaggle/input/test-event-file/1260564881364979717.json\n/kaggle/input/test-event-file/1236670028147314690.json\n/kaggle/input/test-event-file/1250808942189404161.json\n/kaggle/input/test-event-file/524950507023245313.json\n/kaggle/input/test-event-file/1233023914495954946.json\n/kaggle/input/test-event-file/1256305612041814016.json\n/kaggle/input/test-event-file/1242485345037348865.json\n/kaggle/input/test-event-file/1255537146938691584.json\n/kaggle/input/test-event-file/1257232683362660352.json\n/kaggle/input/test-event-file/1270693154698788866.json\n/kaggle/input/test-event-file/407290871856369664.json\n/kaggle/input/test-event-file/1250696428403388419.json\n/kaggle/input/test-event-file/1256358837835030529.json\n/kaggle/input/test-event-file/1243364881757134848.json\n/kaggle/input/test-event-file/1219980594521739265.json\n/kaggle/input/test-event-file/1218250153901076482.json\n/kaggle/input/test-event-file/1244000422882430977.json\n/kaggle/input/test-event-file/614614133410033664.json\n/kaggle/input/test-event-file/1238460460866863105.json\n/kaggle/input/test-event-file/510916725953417218.json\n/kaggle/input/test-event-file/1251056988303364099.json\n/kaggle/input/test-event-file/1243818762211557378.json\n/kaggle/input/test-event-file/482880640560271361.json\n/kaggle/input/test-event-file/1235123649159598084.json\n/kaggle/input/test-event-file/1249614502494187520.json\n/kaggle/input/test-event-file/1251054685538181121.json\n/kaggle/input/test-event-file/524593547807178753.json\n/kaggle/input/test-event-file/1267178201140342785.json\n/kaggle/input/test-event-file/524923341359300608.json\n/kaggle/input/test-event-file/427924694663454720.json\n/kaggle/input/test-event-file/1232924440553496576.json\n/kaggle/input/test-event-file/1240697654222286849.json\n/kaggle/input/test-event-file/1245764856835342338.json\n/kaggle/input/test-event-file/1252195584737452033.json\n/kaggle/input/test-event-file/539254751343681536.json\n/kaggle/input/test-event-file/1243565007805255681.json\n/kaggle/input/test-event-file/1271670872261029889.json\n/kaggle/input/test-event-file/1248605782813392896.json\n/kaggle/input/test-event-file/538256153080127489.json\n/kaggle/input/test-event-file/1256101133736697860.json\n/kaggle/input/test-event-file/1243417698974883843.json\n/kaggle/input/test-event-file/1250004085685678080.json\n/kaggle/input/test-event-file/656818921979310081.json\n/kaggle/input/test-event-file/681147789653356544.json\n/kaggle/input/test-event-file/1243904377456226304.json\n/kaggle/input/test-event-file/1242211013925142530.json\n/kaggle/input/test-event-file/518866406512025602.json\n/kaggle/input/test-event-file/507257950868885504.json\n/kaggle/input/test-event-file/1244916464789970945.json\n/kaggle/input/test-event-file/1222928724112396288.json\n/kaggle/input/test-event-file/515918632178577408.json\n/kaggle/input/test-event-file/1250356617813557250.json\n/kaggle/input/test-event-file/1277760718415245319.json\n/kaggle/input/test-event-file/1237015288589307905.json\n/kaggle/input/test-event-file/489833932813516800.json\n/kaggle/input/test-event-file/1252868603411525632.json\n/kaggle/input/test-event-file/407206094747209728.json\n/kaggle/input/test-event-file/1241235969791209473.json\n/kaggle/input/test-event-file/1234157123531083777.json\n/kaggle/input/test-event-file/1253135163820634112.json\n/kaggle/input/test-event-file/637873886072320001.json\n/kaggle/input/test-event-file/676094756758364160.json\n/kaggle/input/test-event-file/523655026485366784.json\n/kaggle/input/test-event-file/1271506581352562688.json\n/kaggle/input/test-event-file/524947149134774272.json\n/kaggle/input/test-event-file/544698560655400961.json\n/kaggle/input/test-event-file/1276223825793839104.json\n/kaggle/input/test-event-file/1237060019562168320.json\n/kaggle/input/test-event-file/534678919656775680.json\n/kaggle/input/test-event-file/1243443187630342144.json\n/kaggle/input/test-event-file/1237902125704888322.json\n/kaggle/input/test-event-file/514067907475959808.json\n/kaggle/input/test-event-file/1242875894340956161.json\n/kaggle/input/test-event-file/1253477251498164224.json\n/kaggle/input/test-event-file/1254198904331079680.json\n/kaggle/input/test-event-file/1250220987238383616.json\n/kaggle/input/test-event-file/1277836121523838976.json\n/kaggle/input/test-event-file/532007252677656576.json\n/kaggle/input/test-event-file/1251746313487757314.json\n/kaggle/input/test-event-file/1229732608889802753.json\n/kaggle/input/test-event-file/1244476323881336832.json\n/kaggle/input/test-event-file/507557659206516736.json\n/kaggle/input/test-event-file/1239324381215707139.json\n/kaggle/input/test-event-file/514098833253748736.json\n/kaggle/input/test-event-file/1244339469244862466.json\n/kaggle/input/test-event-file/536835346932441088.json\n/kaggle/input/test-event-file/1226929062171545600.json\n/kaggle/input/test-event-file/1225194419843813376.json\n/kaggle/input/test-event-file/498430783699554305.json\n/kaggle/input/test-event-file/1243191807384535040.json\n/kaggle/input/test-event-file/1267237406056558592.json\n/kaggle/input/test-event-file/1239019183398060033.json\n/kaggle/input/test-event-file/1247232361500114948.json\n/kaggle/input/test-event-file/1241330909367939072.json\n/kaggle/input/test-event-file/372901260183494656.json\n/kaggle/input/test-event-file/1274043364149653505.json\n/kaggle/input/test-event-file/534303066867367937.json\n/kaggle/input/test-event-file/1268224832380043264.json\n/kaggle/input/test-event-file/1242365913430667266.json\n/kaggle/input/test-event-file/633949800761700352.json\n/kaggle/input/test-event-file/1238028753659256832.json\n/kaggle/input/test-event-file/1233005480672473091.json\n/kaggle/input/test-event-file/674301960787505153.json\n/kaggle/input/test-event-file/1256093654147428353.json\n/kaggle/input/test-event-file/1238206094050308097.json\n/kaggle/input/test-event-file/647464349611589632.json\n/kaggle/input/test-event-file/553098571323437056.json\n/kaggle/input/test-event-file/1235127762467377152.json\n/kaggle/input/test-event-file/547803254516490240.json\n/kaggle/input/test-event-file/509152237503778816.json\n/kaggle/input/test-event-file/1251310985094316033.json\n/kaggle/input/test-event-file/1255992805672902656.json\n/kaggle/input/test-event-file/489812926828924928.json\n/kaggle/input/test-event-file/1250220272306638848.json\n/kaggle/input/test-event-file/1244004581010550785.json\n/kaggle/input/test-event-file/536849906997415936.json\n/kaggle/input/test-event-file/1242485261734301702.json\n/kaggle/input/test-event-file/1246482832316301319.json\n/kaggle/input/test-event-file/1222922750546923521.json\n/kaggle/input/test-event-file/560474897013415936.json\n/kaggle/input/test-event-file/1239895097040416769.json\n/kaggle/input/test-event-file/544476808566276097.json\n/kaggle/input/test-event-file/1243448361484763137.json\n/kaggle/input/test-event-file/1244705540065955847.json\n/kaggle/input/test-event-file/1225687482139758594.json\n/kaggle/input/test-event-file/1225687455317151744.json\n/kaggle/input/test-event-file/1254482034824638464.json\n/kaggle/input/test-event-file/542860306603868160.json\n/kaggle/input/test-event-file/531659884430106624.json\n/kaggle/input/test-event-file/1242958703436824576.json\n/kaggle/input/test-event-file/1257607679767347201.json\n/kaggle/input/test-event-file/552498516225179650.json\n/kaggle/input/test-event-file/656811196218286080.json\n/kaggle/input/test-event-file/553590459688570880.json\n/kaggle/input/test-event-file/1273583902469361664.json\n/kaggle/input/test-event-file/1239510439920316416.json\n/kaggle/input/test-event-file/553531413459660800.json\n/kaggle/input/test-event-file/1221500792005447680.json\n/kaggle/input/test-event-file/614599815280857088.json\n/kaggle/input/test-event-file/1248769413043683328.json\n/kaggle/input/test-event-file/1223521041793847297.json\n/kaggle/input/test-event-file/1248525457286258689.json\n/kaggle/input/test-event-file/1241406592920064000.json\n/kaggle/input/test-event-file/628681462976528384.json\n/kaggle/input/test-event-file/1225095857583927299.json\n/kaggle/input/test-event-file/1252306840374951938.json\n/kaggle/input/test-event-file/531183173443801088.json\n/kaggle/input/test-event-file/1239310280557019139.json\n/kaggle/input/test-event-file/635632641635667968.json\n/kaggle/input/test-event-file/553061846081896449.json\n/kaggle/input/test-event-file/365276206381268995.json\n/kaggle/input/test-event-file/1268842488980221953.json\n/kaggle/input/test-event-file/1240894108316643329.json\n/kaggle/input/test-event-file/1244717429609189381.json\n/kaggle/input/test-event-file/1243616343976534016.json\n/kaggle/input/test-event-file/524923462398513152.json\n/kaggle/input/test-event-file/614608936491188225.json\n/kaggle/input/test-event-file/1243353600186818560.json\n/kaggle/input/test-event-file/618805892222468096.json\n/kaggle/input/test-event-file/489836441120145408.json\n/kaggle/input/test-event-file/538218607822770176.json\n/kaggle/input/test-event-file/1237274979315724288.json\n/kaggle/input/test-event-file/524685073979678721.json\n/kaggle/input/test-event-file/1257079462748844033.json\n/kaggle/input/test-event-file/1253645219188355073.json\n/kaggle/input/test-event-file/1245989574905602050.json\n/kaggle/input/test-event-file/1242485439665041408.json\n/kaggle/input/test-event-file/1250659810044829696.json\n/kaggle/input/test-event-file/1237162887812124673.json\n/kaggle/input/test-event-file/641443248909754368.json\n/kaggle/input/test-event-file/1237267351088910336.json\n/kaggle/input/test-event-file/1248666174042374144.json\n/kaggle/input/test-event-file/1260958031518609408.json\n/kaggle/input/test-event-file/1239843424691339264.json\n/kaggle/input/test-event-file/1259642066663079939.json\n/kaggle/input/test-event-file/1248769427648253954.json\n/kaggle/input/test-event-file/668144671772778497.json\n/kaggle/input/test-event-file/527295015643394048.json\n/kaggle/input/test-event-file/1234566237314666496.json\n/kaggle/input/test-event-file/552792913910833152.json\n/kaggle/input/test-event-file/1253959004436467713.json\n/kaggle/input/test-event-file/618804516578680832.json\n/kaggle/input/test-event-file/1222929006967869442.json\n/kaggle/input/test-event-file/1244912804844523521.json\n/kaggle/input/test-event-file/1252281210384064512.json\n/kaggle/input/test-event-file/542600886653292545.json\n/kaggle/input/test-event-file/1265298431670734848.json\n/kaggle/input/test-event-file/614638036593299456.json\n/kaggle/input/test-event-file/1250202120076161025.json\n/kaggle/input/test-event-file/675065047710892033.json\n/kaggle/input/test-event-file/1252284632483020814.json\n/kaggle/input/test-event-file/543319210659971073.json\n/kaggle/input/test-event-file/1238926528454385664.json\n/kaggle/input/test-event-file/1246917232631955464.json\n/kaggle/input/test-event-file/504304227246538752.json\n/kaggle/input/test-event-file/551103664124100608.json\n/kaggle/input/test-event-file/1277610026404917248.json\n/kaggle/input/test-event-file/528976109518721024.json\n/kaggle/input/test-event-file/1244143623635116033.json\n/kaggle/input/test-event-file/544512664769396736.json\n/kaggle/input/test-event-file/1236050331940855808.json\n/kaggle/input/test-event-file/1242069705633882112.json\n/kaggle/input/test-event-file/1235239045187268613.json\n/kaggle/input/test-event-file/509478961705807872.json\n/kaggle/input/test-event-file/1242578357495218176.json\n/kaggle/input/test-event-file/489829414704648192.json\n/kaggle/input/test-event-file/1248778880262995968.json\n/kaggle/input/test-event-file/527138218505175040.json\n/kaggle/input/test-event-file/1246756358608871424.json\n/kaggle/input/test-event-file/513749585391390720.json\n/kaggle/input/test-event-file/523863683928457216.json\n/kaggle/input/test-event-file/626739062792032256.json\n/kaggle/input/test-event-file/553186555150749696.json\n/kaggle/input/test-event-file/1248670865182556170.json\n/kaggle/input/test-event-file/1236627989036781569.json\n/kaggle/input/test-event-file/531833233143783424.json\n/kaggle/input/test-event-file/1248616431802920961.json\n/kaggle/input/test-event-file/407163869673443328.json\n/kaggle/input/test-event-file/1248608866167742467.json\n/kaggle/input/test-event-file/1227148217394978817.json\n/kaggle/input/test-event-file/1254035404799516674.json\n/kaggle/input/test-event-file/407231591191035904.json\n/kaggle/input/test-event-file/1251054690588135425.json\n/kaggle/input/test-event-file/1240341381773549568.json\n/kaggle/input/test-event-file/1239139106451386374.json\n/kaggle/input/test-event-file/1242958702556016640.json\n/kaggle/input/test-event-file/1223993219022753793.json\n/kaggle/input/test-event-file/1249596439174557696.json\n/kaggle/input/test-event-file/662430295254175744.json\n/kaggle/input/test-event-file/489902412900343809.json\n/kaggle/input/test-event-file/553099685888790528.json\n/kaggle/input/test-event-file/1235105420252856321.json\n/kaggle/input/test-event-file/673079581520318464.json\n/kaggle/input/test-event-file/407191058108256257.json\n/kaggle/input/test-event-file/518665533089406976.json\n/kaggle/input/test-event-file/613294443878305796.json\n/kaggle/input/test-event-file/525088864416043008.json\n/kaggle/input/test-event-file/455525437351800832.json\n/kaggle/input/test-event-file/1251924696519471105.json\n/kaggle/input/test-event-file/1232924379274719234.json\n/kaggle/input/test-event-file/518830518792892416.json\n/kaggle/input/test-event-file/524976980799000578.json\n/kaggle/input/test-event-file/1241329705522999297.json\n/kaggle/input/test-event-file/641088973717110784.json\n/kaggle/input/test-event-file/1252938233249443840.json\n/kaggle/input/test-event-file/1248121143808098305.json\n/kaggle/input/test-event-file/544504183341064192.json\n/kaggle/input/test-event-file/550038665653542913.json\n/kaggle/input/test-event-file/1235970785002561537.json\n/kaggle/input/test-event-file/537355288295518210.json\n/kaggle/input/test-event-file/673581371458199552.json\n/kaggle/input/test-event-file/1277286871651975168.json\n/kaggle/input/test-event-file/1246921819073982464.json\n/kaggle/input/test-event-file/1241328689436135425.json\n/kaggle/input/test-event-file/489836271049928704.json\n/kaggle/input/test-event-file/544268732046913536.json\n/kaggle/input/test-event-file/1233113048120020994.json\n/kaggle/input/test-event-file/651825062174195712.json\n/kaggle/input/test-event-file/580348081100734464.json\n/kaggle/input/test-event-file/427666815842414592.json\n/kaggle/input/test-event-file/1239325309134086145.json\n/kaggle/input/test-event-file/551106793959862272.json\n/kaggle/input/test-event-file/1238424497700691970.json\n/kaggle/input/test-event-file/1242460228517535744.json\n/kaggle/input/test-event-file/1260920875165024262.json\n/kaggle/input/test-event-file/1244705530595151873.json\n/kaggle/input/test-event-file/1252408181260603395.json\n/kaggle/input/test-event-file/663904307113275392.json\n/kaggle/input/test-event-file/1238410449823072256.json\n/kaggle/input/test-event-file/1239326621514915840.json\n/kaggle/input/test-event-file/1237868142463840262.json\n/kaggle/input/test-event-file/1221831204418334721.json\n/kaggle/input/test-event-file/1240948885910179841.json\n/kaggle/input/test-event-file/1275291205639778304.json\n/kaggle/input/test-event-file/1248902780556693506.json\n/kaggle/input/test-event-file/491200302365040640.json\n/kaggle/input/test-event-file/620367840902782976.json\n/kaggle/input/test-event-file/1243651257912430593.json\n/kaggle/input/test-event-file/1242587275776516096.json\n/kaggle/input/test-event-file/524962676665888769.json\n/kaggle/input/test-event-file/1256259379856277504.json\n/kaggle/input/test-event-file/1244915128987979777.json\n/kaggle/input/test-event-file/644229386149888001.json\n/kaggle/input/test-event-file/524944881941495809.json\n/kaggle/input/test-event-file/1249209381813714944.json\n/kaggle/input/test-event-file/1268702744870678528.json\n/kaggle/input/test-event-file/544382892378714113.json\n/kaggle/input/test-event-file/1245824031510667265.json\n/kaggle/input/test-event-file/1233565837073608704.json\n/kaggle/input/test-event-file/1240721296511598592.json\n/kaggle/input/test-event-file/1243173672841601027.json\n/kaggle/input/test-event-file/377519445578895360.json\n/kaggle/input/test-event-file/1224095170477481984.json\n/kaggle/input/test-event-file/1248769432748466177.json\n/kaggle/input/test-event-file/531206167302012929.json\n/kaggle/input/test-event-file/366025766183514112.json\n/kaggle/input/test-event-file/1230539788488495108.json\n/kaggle/input/test-event-file/518924377791164420.json\n/kaggle/input/test-event-file/1229508745677414405.json\n/kaggle/input/test-event-file/1243384220845608961.json\n/kaggle/input/test-event-file/407237676350185475.json\n/kaggle/input/test-event-file/525024181218725888.json\n/kaggle/input/test-event-file/1239915291196473345.json\n/kaggle/input/test-event-file/629503919098429440.json\n/kaggle/input/test-event-file/1255175204348858370.json\n/kaggle/input/test-event-file/1237312079440285696.json\n/kaggle/input/test-event-file/673615263040798726.json\n/kaggle/input/test-event-file/1252315501214273537.json\n/kaggle/input/test-event-file/1242015452332806144.json\n/kaggle/input/test-event-file/647169573599449088.json\n/kaggle/input/test-event-file/1241107812551458816.json\n/kaggle/input/test-event-file/1239557784666071040.json\n/kaggle/input/test-event-file/656830586577883136.json\n/kaggle/input/test-event-file/1256246327903752193.json\n/kaggle/input/test-event-file/1270704437577818113.json\n/kaggle/input/test-event-file/1245172237977767936.json\n/kaggle/input/test-event-file/489872119158046720.json\n/kaggle/input/test-event-file/1264311672057069568.json\n/kaggle/input/test-event-file/1269660260299669504.json\n/kaggle/input/test-event-file/1252678658860306432.json\n/kaggle/input/test-event-file/1239188532259966978.json\n/kaggle/input/test-event-file/1258787515592572928.json\n/kaggle/input/test-event-file/1238775642042372096.json\n/kaggle/input/test-event-file/1237712886459490304.json\n/kaggle/input/test-event-file/1250142275084136448.json\n/kaggle/input/test-event-file/519929168864497664.json\n/kaggle/input/test-event-file/544515538383564801.json\n/kaggle/input/test-event-file/1223521014195376128.json\n/kaggle/input/test-event-file/1244610406355779584.json\n/kaggle/input/test-event-file/524975705206304769.json\n/kaggle/input/test-event-file/370855596050108416.json\n/kaggle/input/test-event-file/524979548195024898.json\n/kaggle/input/test-event-file/1243757859676000257.json\n/kaggle/input/test-event-file/544491151118860289.json\n/kaggle/input/test-event-file/651959206287908868.json\n/kaggle/input/test-event-file/636925368927064064.json\n/kaggle/input/test-event-file/1219977126742544384.json\n/kaggle/input/test-event-file/1249866103586578432.json\n/kaggle/input/test-event-file/1264249669044977669.json\n/kaggle/input/test-event-file/560207034545889281.json\n/kaggle/input/test-event-file/523126268603031552.json\n/kaggle/input/test-event-file/521717368264093696.json\n/kaggle/input/test-event-file/568905632998412288.json\n/kaggle/input/test-event-file/407170170533064705.json\n/kaggle/input/test-event-file/1251435176980332555.json\n/kaggle/input/test-event-file/1243559430958039041.json\n/kaggle/input/test-event-file/532208816692416512.json\n/kaggle/input/test-event-file/1249529725019738113.json\n/kaggle/input/test-event-file/661299012386095105.json\n/kaggle/input/test-event-file/1236050255394877440.json\n/kaggle/input/test-event-file/555072815154475008.json\n/kaggle/input/test-event-file/1255451744492019712.json\n/kaggle/input/test-event-file/1224201250876489729.json\n/kaggle/input/test-event-file/1237030008067166208.json\n/kaggle/input/test-event-file/1244895539394572288.json\n/kaggle/input/test-event-file/650128194209730561.json\n/kaggle/input/test-event-file/1276173226171863042.json\n/kaggle/input/test-event-file/1240237378041778176.json\n/kaggle/input/test-event-file/1236627986717323264.json\n/kaggle/input/test-event-file/1242034279841841154.json\n/kaggle/input/test-event-file/531129816389779456.json\n/kaggle/input/test-event-file/509464457836511232.json\n/kaggle/input/test-event-file/1221834674386997249.json\n/kaggle/input/test-event-file/1270708758642135041.json\n/kaggle/input/test-event-file/524991067675189250.json\n/kaggle/input/test-event-file/1242153442208026632.json\n/kaggle/input/test-event-file/1242070704310243330.json\n/kaggle/input/test-event-file/1245512289278668800.json\n/kaggle/input/test-event-file/525049639016615937.json\n/kaggle/input/test-event-file/1254624942433251328.json\n/kaggle/input/test-event-file/1265668003301130242.json\n/kaggle/input/test-event-file/1239536001665638400.json\n/kaggle/input/test-event-file/1238325240536551424.json\n/kaggle/input/test-event-file/1276549651265654786.json\n/kaggle/input/test-event-file/524928119955013632.json\n/kaggle/input/test-event-file/1234884644870352896.json\n/kaggle/input/test-event-file/1235239041441943554.json\n/kaggle/input/test-event-file/531568534066057217.json\n/kaggle/input/test-event-file/407163499723624449.json\n/kaggle/input/test-event-file/1223585697778556928.json\n/kaggle/input/test-event-file/1258487399014858752.json\n/kaggle/input/test-event-file/614790312955904000.json\n/kaggle/input/test-event-file/1239656563029217281.json\n/kaggle/input/test-event-file/525033697045925888.json\n/kaggle/input/test-event-file/656825206045020160.json\n/kaggle/input/test-event-file/1242161191960678401.json\n/kaggle/input/test-event-file/501785003144273921.json\n/kaggle/input/test-event-file/1238510064027209730.json\n/kaggle/input/test-event-file/1277033220433993732.json\n/kaggle/input/test-event-file/615840865815298048.json\n/kaggle/input/test-event-file/516729950091493376.json\n/kaggle/input/test-event-file/1245736128734527488.json\n/kaggle/input/test-event-file/1251054694014824448.json\n/kaggle/input/test-event-file/535252460148113409.json\n/kaggle/input/test-event-file/1226812599569932288.json\n/kaggle/input/test-event-file/1247237838485237763.json\n/kaggle/input/test-event-file/1249188918500753416.json\n/kaggle/input/test-event-file/1232541995815571456.json\n/kaggle/input/test-event-file/1233555360826265600.json\n/kaggle/input/test-event-file/1240302223881625600.json\n/kaggle/input/test-event-file/1251522113141215232.json\n/kaggle/input/test-event-file/1263122359994781696.json\n/kaggle/input/test-event-file/1241805420181757957.json\n/kaggle/input/test-event-file/1249019022164799488.json\n/kaggle/input/test-event-file/1240324491986731008.json\n/kaggle/input/test-event-file/614593386188828672.json\n/kaggle/input/test-event-file/1249341627824390155.json\n/kaggle/input/test-event-file/1222182262130823168.json\n/kaggle/input/test-event-file/80080680482123777.json\n/kaggle/input/test-event-file/1229770637880840194.json\n/kaggle/input/test-event-file/1252469613176082440.json\n/kaggle/input/test-event-file/656595123590012928.json\n/kaggle/input/test-event-file/1242350943443865600.json\n/kaggle/input/test-event-file/427944719612915712.json\n/kaggle/input/test-event-file/501881262240694272.json\n/kaggle/input/test-event-file/1278262917360693248.json\n/kaggle/input/test-event-file/1241390215656333312.json\n/kaggle/input/test-event-file/1245272393712615425.json\n/kaggle/input/test-event-file/518827403452637184.json\n/kaggle/input/test-event-file/1237770514954956801.json\n/kaggle/input/test-event-file/1237162888869093376.json\n/kaggle/input/test-event-file/1242088874924441602.json\n/kaggle/input/test-event-file/614626710248534016.json\n/kaggle/input/test-event-file/500378223977721856.json\n/kaggle/input/test-event-file/544391533240516608.json\n/kaggle/input/test-event-file/1253630441338179585.json\n/kaggle/input/test-event-file/1248524574217490432.json\n/kaggle/input/test-event-file/552832817089236992.json\n/kaggle/input/test-event-file/1252978963426803712.json\n/kaggle/input/test-event-file/387220814531395584.json\n/kaggle/input/test-event-file/552792544132997121.json\n/kaggle/input/test-event-file/535579674152148992.json\n/kaggle/input/test-event-file/1255630453949837318.json\n/kaggle/input/test-event-file/1225687494886191104.json\n/kaggle/input/test-event-file/1264846216761872388.json\n/kaggle/input/test-event-file/524923293711998976.json\n/kaggle/input/test-event-file/1235834475348496385.json\n/kaggle/input/test-event-file/1242756999240208385.json\n/kaggle/input/test-event-file/524941504796962816.json\n/kaggle/input/test-event-file/1243285526850859008.json\n/kaggle/input/test-event-file/1241325788395233280.json\n/kaggle/input/test-event-file/1252279738099433473.json\n/kaggle/input/test-event-file/1248525002028146688.json\n/kaggle/input/test-event-file/1277199351639654404.json\n/kaggle/input/test-event-file/1239251546275221506.json\n/kaggle/input/test-event-file/1234884632627122176.json\n/kaggle/input/test-event-file/1232924186219339777.json\n/kaggle/input/test-event-file/1250258210243698688.json\n/kaggle/input/test-event-file/1263985744940589058.json\n/kaggle/input/test-event-file/535474881090322432.json\n/kaggle/input/test-event-file/1240989772866338816.json\n/kaggle/input/test-event-file/1274896295472377856.json\n/kaggle/input/test-event-file/376874273601630208.json\n/kaggle/input/test-event-file/387281927427727360.json\n/kaggle/input/test-event-file/1235122005004804098.json\n/kaggle/input/test-event-file/1250492351069511681.json\n/kaggle/input/test-event-file/407173794583695360.json\n/kaggle/input/test-event-file/1250219116993974272.json\n/kaggle/input/test-event-file/663722803489808384.json\n/kaggle/input/test-event-file/1238211457000427520.json\n/kaggle/input/test-event-file/532276370953752576.json\n/kaggle/input/test-event-file/1278071380161048576.json\n/kaggle/input/project-data/train.label.txt\n/kaggle/input/project-data/train.data.txt\n/kaggle/input/project-data/test.data.txt\n/kaggle/input/project-data/dev.label.txt\n/kaggle/input/project-data/dev.data.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport csv\nimport re\nimport torch\nimport pandas as pd\nimport time\nimport operator\nimport math\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\nfrom torch.optim import AdamW\nimport torch.nn as nn\nfrom torch.nn import CrossEntropyLoss, MSELoss\nfrom transformers import BertModel, BertTokenizer, BertPreTrainedModel, AdamW\nfrom sklearn import preprocessing\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:17:16.886866Z","iopub.execute_input":"2022-05-12T11:17:16.887115Z","iopub.status.idle":"2022-05-12T11:17:23.980280Z","shell.execute_reply.started":"2022-05-12T11:17:16.887088Z","shell.execute_reply":"2022-05-12T11:17:23.979567Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Task 1","metadata":{}},{"cell_type":"code","source":"DEV_FILE = '/kaggle/input/preprocessed-data/dev.csv'\nTRAIN_FILE = '/kaggle/input/preprocessed-data/train.csv'\nTEST_FILE = '/kaggle/input/preprocessed-data/test.csv'\n\n# over-sampling non-rumour data\ntrain_set = pd.read_csv(TRAIN_FILE)\ntrain_set_rumour_idx = train_set.index[train_set['Label'] == 'rumour'].tolist()\nratio = math.floor(train_set['Label'].value_counts()[0]/train_set['Label'].value_counts()[1])\nwhile ratio:\n    train_set = pd.concat([train_set, train_set.loc[train_set_rumour_idx]], ignore_index=True, axis=0)\n    ratio -= 1\ntrain_set.to_csv('./train.csv', index = False)\nTRAIN_FILE = '/kaggle/working/train.csv'\n\ndev_set = pd.read_csv(DEV_FILE)\ndev_set_rumour_idx = dev_set.index[dev_set['Label'] == 'rumour'].tolist()\nratio = math.floor(dev_set['Label'].value_counts()[0]/dev_set['Label'].value_counts()[1])\nwhile ratio:\n    dev_set = pd.concat([dev_set, dev_set.loc[dev_set_rumour_idx]], ignore_index=True, axis=0)\n    ratio -= 1\ndev_set.to_csv('./dev.csv', index = False)\nDEV_FILE = '/kaggle/working/dev.csv'","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:03:46.222967Z","iopub.execute_input":"2022-05-12T08:03:46.22327Z","iopub.status.idle":"2022-05-12T08:03:46.521346Z","shell.execute_reply.started":"2022-05-12T08:03:46.223225Z","shell.execute_reply":"2022-05-12T08:03:46.520312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converts 'nonrumour' to 0 and 'rumour' to 1 in the list of labels in both training and development sets\nlabel_encoder = preprocessing.LabelEncoder()\nlabel_encoder.fit(['nonrumour', 'rumour'])\n\ntrain_events = pd.read_csv(TRAIN_FILE)\ntrain_events['Label'] = label_encoder.transform(train_events['Label'])\ndev_events = pd.read_csv(DEV_FILE)\ndev_events['Label'] = label_encoder.transform(dev_events['Label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:03:46.524086Z","iopub.execute_input":"2022-05-12T08:03:46.524363Z","iopub.status.idle":"2022-05-12T08:03:46.590555Z","shell.execute_reply.started":"2022-05-12T08:03:46.524323Z","shell.execute_reply":"2022-05-12T08:03:46.589623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute the class weights for the loss function later on\n#class_weights = compute_class_weight(class_weight = 'balanced', classes = list(set(train_events['Label'])), y = train_events['Label'])\n#weights = torch.tensor(class_weights, dtype = torch.float)\n#weights = weights.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:03:46.592301Z","iopub.execute_input":"2022-05-12T08:03:46.592589Z","iopub.status.idle":"2022-05-12T08:03:46.598939Z","shell.execute_reply.started":"2022-05-12T08:03:46.592548Z","shell.execute_reply":"2022-05-12T08:03:46.597988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_split(text):\n    #text = text.replace('[CLS]','')\n    #text = text.replace('[SEP]','')\n    new_text = ''\n    curr_text = ''\n    \n    for word in text.split():\n        curr_text += word + ' '\n        \n        if word == '[SEP]':\n            new_text += curr_text\n            curr_text = ''\n            \n    new_text = new_text[:-1]\n    \n    return new_text\n\nsplit_train_events = train_events.copy()\nsplit_train_events['Event Tweets'] = split_train_events['Event Tweets'].apply(text_split)\nsplit_dev_events = dev_events.copy()\nsplit_dev_events['Event Tweets'] = split_dev_events['Event Tweets'].apply(text_split)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:03:46.602192Z","iopub.execute_input":"2022-05-12T08:03:46.602742Z","iopub.status.idle":"2022-05-12T08:03:46.859249Z","shell.execute_reply.started":"2022-05-12T08:03:46.602694Z","shell.execute_reply":"2022-05-12T08:03:46.858281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finds the max length of all the tweets for both the training and development\ntrain_max = 0\ncurr_count = 0\n\nfor i in split_train_events['Event Tweets']:\n    for j in i.split():\n        curr_count += 1\n        if j == '[SEP]':\n            if curr_count > train_max:\n                train_max = curr_count\n            curr_count = 0\n        \ndev_max = 0\ncurr_count = 0\n\nfor i in split_dev_events['Event Tweets']:\n    for j in i.split():\n        curr_count += 1\n        if j == '[SEP]':\n            if curr_count > dev_max:\n                dev_max = curr_count\n            curr_count = 0\n        \n# max counts used for padding later on\nprint(\"Training set has a max sentence length of\", train_max)\nprint(\"Development set has a max sentence length of\", dev_max)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:03:46.860749Z","iopub.execute_input":"2022-05-12T08:03:46.861048Z","iopub.status.idle":"2022-05-12T08:03:47.045082Z","shell.execute_reply.started":"2022-05-12T08:03:46.860994Z","shell.execute_reply":"2022-05-12T08:03:47.043771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# our main BERT classifier model\nclass BertClassifier(nn.Module):\n\n    def __init__(self, bert_base):\n        super(BertClassifier, self).__init__()\n        self.bert = bert_base\n        self.dropout = nn.Dropout(0.3)\n        self.relu = nn.ReLU()\n        self.in = nn.Linear(768,512)\n        self.out = nn.Linear(512, 2)\n        self.softmax = nn.LogSoftmax(dim = 1)\n\n    def forward(self, input_ids, attention_mask):\n        \n        _, inputs = self.bert(input_ids, attention_mask = attention_mask, return_dict = False)\n        \n        x = self.in(inputs)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.out(x)\n        x = self.softmax(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:03:47.047067Z","iopub.execute_input":"2022-05-12T08:03:47.047371Z","iopub.status.idle":"2022-05-12T08:03:47.056222Z","shell.execute_reply.started":"2022-05-12T08:03:47.04733Z","shell.execute_reply":"2022-05-12T08:03:47.055236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_base = BertModel.from_pretrained('bert-base-uncased')\nmodel = BertClassifier(bert_base)\nmodel.to('cuda')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n\n# batch_encode_plus tokenizes and prepares a list of ids using the BERT word embeddings dictionary and attention masks\n# which include padding with a max length to consider the padding for\ntrain_tokens = tokenizer.batch_encode_plus(\n    list(split_train_events['Event Tweets']),\n    add_special_tokens = False,\n    max_length = train_max,\n    pad_to_max_length = True,\n    truncation = True\n)\n\ndev_tokens = tokenizer.batch_encode_plus(\n    list(split_dev_events['Event Tweets']),\n    add_special_tokens = False,\n    max_length = dev_max,\n    pad_to_max_length = True,\n    truncation = True\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:04:10.23681Z","iopub.execute_input":"2022-05-12T08:04:10.23731Z","iopub.status.idle":"2022-05-12T08:04:48.400666Z","shell.execute_reply.started":"2022-05-12T08:04:10.237265Z","shell.execute_reply":"2022-05-12T08:04:48.399614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the lists of ids, attention masks, and labels to tensors to be read into tensor datasets to form\n# the samplers and data loaders\ntrain_ids = torch.tensor(train_tokens['input_ids'])\ntrain_mask = torch.tensor(train_tokens['attention_mask'])\ntrain_y = torch.tensor((list(split_train_events['Label'])))\ntrain_data = TensorDataset(train_ids, train_mask, train_y)\ntrain_sampler = RandomSampler(train_data)\ntrain_loader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n\ndev_ids = torch.tensor(dev_tokens['input_ids'])\ndev_mask = torch.tensor(dev_tokens['attention_mask'])\ndev_y = torch.tensor(list(split_dev_events['Label']))\ndev_data = TensorDataset(dev_ids, dev_mask, dev_y)\ndev_sampler = RandomSampler(dev_data)\ndev_loader = DataLoader(dev_data, sampler = dev_sampler, batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:04:48.402243Z","iopub.execute_input":"2022-05-12T08:04:48.403615Z","iopub.status.idle":"2022-05-12T08:04:48.47852Z","shell.execute_reply.started":"2022-05-12T08:04:48.403567Z","shell.execute_reply":"2022-05-12T08:04:48.477345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    model.train()\n    total_loss = 0.0\n    total_acc = 0.0\n    total = 0\n    \n    # for each batch\n    for step, (ids, masks, labels) in enumerate(train_loader):            \n        ids, masks, labels = ids.to('cuda'), masks.to('cuda'), labels.to('cuda')\n        \n        model.zero_grad() # clears gradients\n\n        preds = model(ids, masks)\n\n        loss = criterion(preds, labels)\n        \n        # l2 regularisation\n        l2_norm = sum(param.pow(2.0).sum() for param in model.parameters())\n        loss = loss + l_lambda * l2_norm\n        \n        # l1 regularisation\n        #l1_norm = sum(param.abs().sum() for param in model.parameters())\n        #loss = loss + l_lambda * l1_norm\n        \n        loss.backward() # computes gradient during neural network backward pass\n        total_loss = total_loss + loss.item()\n\n        # used to prevent the \"exploding gradients\" problem\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        \n        # update parameters\n        opti.step()\n\n        _, predicts = preds.max(1)\n        total += labels.size(0)\n        total_acc += predicts.eq(labels).sum().item()\n        \n    avg_loss = total_loss / len(train_loader)\n    total_acc = total_acc / total\n    \n    return avg_loss, total_acc","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:04:48.480353Z","iopub.execute_input":"2022-05-12T08:04:48.48076Z","iopub.status.idle":"2022-05-12T08:04:48.492783Z","shell.execute_reply.started":"2022-05-12T08:04:48.480682Z","shell.execute_reply":"2022-05-12T08:04:48.491763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate():\n    model.eval()\n    total_loss = 0.0\n    total_acc = 0.0\n    total = 0\n\n    # for each batch\n    for step, (ids, masks, labels) in enumerate(dev_loader):\n        ids, masks, labels = ids.to('cuda'), masks.to('cuda'), labels.to('cuda')\n\n        with torch.no_grad():\n            preds = model(ids, masks)\n            \n            loss = criterion(preds, labels)\n            \n            # l2 regularisation\n            l2_norm = sum(param.pow(2.0).sum() for param in model.parameters())\n            loss = loss + l_lambda * l2_norm\n            \n            # l1 regularisation\n            #l1_norm = sum(param.abs().sum() for param in model.parameters())\n            #loss = loss + l_lambda * l1_norm\n            \n            total_loss = total_loss + loss.item()\n            \n            _, predicts = preds.max(1)\n            total += labels.size(0)\n            total_acc += predicts.eq(labels).sum().item()\n        \n    avg_loss = total_loss / len(train_loader)\n    total_acc = total_acc / total\n    \n    return avg_loss, total_acc","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:04:48.494379Z","iopub.execute_input":"2022-05-12T08:04:48.495253Z","iopub.status.idle":"2022-05-12T08:04:48.510627Z","shell.execute_reply.started":"2022-05-12T08:04:48.495212Z","shell.execute_reply":"2022-05-12T08:04:48.50935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# other parameters for the training and evaluation process\nopti = AdamW(model.parameters(), lr = 2e-5)    # AdamW optimiser\ncriterion = nn.NLLLoss()                       # negative log-likelihood loss function\nl_lambda = 0.0001                              # lambda for l1/l2 regularisation\nmax_epochs = 10\nbatch_size = 3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_dev_loss = float('inf')\n\ntrain_loses = []\ndev_loses = []\n\n# actual training and evaluation occurs here for each epoch\nfor ep in range(max_epochs):\n    print(\"Epoch \" + str(ep + 1) + \":\")\n    \n    train_loss, train_acc = train()\n    dev_loss, dev_acc = evaluate()\n    \n    # judges value based on development loss rather than development accuracy\n    if dev_loss < best_dev_loss:\n        best_dev_loss = dev_loss\n        torch.save(model.state_dict(), 'best_weights.pt') # saves the weights of the model of the current epoch\n        \n    train_loses.append(train_loss)\n    dev_loses.append(dev_loss)\n    \n    print(\"Training Loss:   \", train_loss, \"Training Accuracy:   \", train_acc)\n    print(\"Development Loss:\", dev_loss, \"Development Accuracy:\", dev_acc, \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:04:48.512478Z","iopub.execute_input":"2022-05-12T08:04:48.512838Z","iopub.status.idle":"2022-05-12T08:25:48.328252Z","shell.execute_reply.started":"2022-05-12T08:04:48.51278Z","shell.execute_reply":"2022-05-12T08:25:48.324592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# same processes as for the training and development sets but for the test set\ntest_events = pd.read_csv(TEST_FILE)\nsplit_test_events = test_events.copy()\nsplit_test_events['Event Tweets'] = split_test_events['Event Tweets'].apply(text_split)\n\ntest_max = 0\ncurr_count = 0\n\nfor i in split_test_events['Event Tweets']:\n    for j in i.split():\n        curr_count += 1\n        if j == '[SEP]':\n            if curr_count > test_max:\n                test_max = curr_count\n            curr_count = 0\n            \nprint(\"Test set has a max sentence length of\", test_max)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:25:48.330202Z","iopub.execute_input":"2022-05-12T08:25:48.330532Z","iopub.status.idle":"2022-05-12T08:25:48.426299Z","shell.execute_reply.started":"2022-05-12T08:25:48.330489Z","shell.execute_reply":"2022-05-12T08:25:48.425246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_tokens = tokenizer.batch_encode_plus(\n    list(split_test_events['Event Tweets']),\n    add_special_tokens = False,\n    max_length = train_max,\n    pad_to_max_length = True,\n    truncation = True\n)\n\ntest_ids = torch.tensor(test_tokens['input_ids'])\ntest_mask = torch.tensor(test_tokens['attention_mask'])\n\ntest_data = TensorDataset(test_ids, test_mask)\ntest_sampler = RandomSampler(test_data)\ntest_loader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:25:48.427968Z","iopub.execute_input":"2022-05-12T08:25:48.428547Z","iopub.status.idle":"2022-05-12T08:25:52.155638Z","shell.execute_reply.started":"2022-05-12T08:25:48.428501Z","shell.execute_reply":"2022-05-12T08:25:52.154683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weight_file = f'best_weights.pt'\nmodel.load_state_dict(torch.load(weight_file)) # loads the best recorded weights during the best epoch\n\nwith torch.no_grad():\n    preds = model(test_ids.to('cuda'), test_mask.to('cuda'))\n    preds = preds.detach().cpu().numpy() # gets the prediction labels from the GPU by pushing it to the CPU\n    preds = np.argmax(preds, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:25:52.157356Z","iopub.execute_input":"2022-05-12T08:25:52.157673Z","iopub.status.idle":"2022-05-12T08:25:53.353971Z","shell.execute_reply.started":"2022-05-12T08:25:52.157629Z","shell.execute_reply":"2022-05-12T08:25:53.352963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/final.csv', 'w', newline='') as o:\n    csv_write = csv.writer(o)\n    csv_write.writerow(['Id', 'Predicted'])\n\n    for i in range(len(preds)):\n        idx = i\n        is_rumour = preds[i]\n        csv_write.writerow([idx, is_rumour])","metadata":{"execution":{"iopub.status.busy":"2022-05-12T08:25:53.355732Z","iopub.execute_input":"2022-05-12T08:25:53.356234Z","iopub.status.idle":"2022-05-12T08:25:53.36623Z","shell.execute_reply.started":"2022-05-12T08:25:53.356189Z","shell.execute_reply":"2022-05-12T08:25:53.365061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Task 2","metadata":{}},{"cell_type":"code","source":"# to process covid data, no need to run any of the cells in Section 'Task 1', just those in this section\n# some of these cells are repeats from above as we will use them in this section\n# if 'Task 1' cells have been run skip running cells labelled \"SKIP\"\n# SKIP\ndef text_split(text):\n    #text = text.replace('[CLS]','')\n    #text = text.replace('[SEP]','')\n    new_text = ''\n    curr_text = ''\n    \n    for word in text.split():\n        curr_text += word + ' '\n        \n        if word == '[SEP]':\n            new_text += curr_text\n            curr_text = ''\n            \n    new_text = new_text[:-1]\n    \n    return new_text","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:17:25.909614Z","iopub.execute_input":"2022-05-12T11:17:25.909876Z","iopub.status.idle":"2022-05-12T11:17:25.915070Z","shell.execute_reply.started":"2022-05-12T11:17:25.909848Z","shell.execute_reply":"2022-05-12T11:17:25.914367Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# SKIP\nclass BertClassifier(nn.Module):\n\n    def __init__(self, bert_base):\n        super(BertClassifier, self).__init__()\n        self.bert = bert_base\n        self.dropout = nn.Dropout(0.3)\n        self.relu = nn.ReLU()\n        self.in = nn.Linear(768,512)\n        self.out = nn.Linear(512, 2)\n        self.softmax = nn.LogSoftmax(dim = 1)\n\n    def forward(self, input_ids, attention_mask):\n        \n        _, inputs = self.bert(input_ids, attention_mask = attention_mask, return_dict = False)\n        \n        x = self.in(inputs)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.out(x)\n        x = self.softmax(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:17:26.342002Z","iopub.execute_input":"2022-05-12T11:17:26.342514Z","iopub.status.idle":"2022-05-12T11:17:26.350020Z","shell.execute_reply.started":"2022-05-12T11:17:26.342476Z","shell.execute_reply":"2022-05-12T11:17:26.349369Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# SKIP\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\nbert_base = BertModel.from_pretrained('bert-base-uncased')\nmodel = BertClassifier(bert_base)\nmodel.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:17:26.859722Z","iopub.execute_input":"2022-05-12T11:17:26.860335Z","iopub.status.idle":"2022-05-12T11:17:47.658847Z","shell.execute_reply.started":"2022-05-12T11:17:26.860282Z","shell.execute_reply":"2022-05-12T11:17:47.658166Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2c1c315c1a84441b5813464194f8c97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56e1cd2bc5324915a5d52acb32ba0be6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"205b5363ad56474aaa92ca80e352e6f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f360f486dad48509ce950a293682a40"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"BertClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (relu): ReLU()\n  (fc1): Linear(in_features=768, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=2, bias=True)\n  (softmax): LogSoftmax(dim=1)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# had to breakup the COVID dataset in 2 to be able to process it within the memory limit of 16GB\n# hence covid_1.csv and covid_2.csv\n#COVID_FILE = '/kaggle/input/preprocessed-data/covid_1.csv'\nCOVID_FILE = '/kaggle/input/preprocessed-data/covid_2.csv'\n\ncovid_events = pd.read_csv(COVID_FILE)\nsplit_covid_events = covid_events.copy()\nsplit_covid_events['Event Tweets'] = split_covid_events['Event Tweets'].apply(text_split)\n\nbatch_size = 1 # have to set to 1 as setting to 3 causes memory issues due to size of COVID data\ncovid_max = 30 # similarly with max length of padding, 67 is the actual max length in the COVID dataset\n#curr_count = 0\n\n#for i in split_covid_events['Event Tweets']:\n#    for j in i.split():\n#        curr_count += 1\n#        if j == '[SEP]':\n#            if curr_count > covid_max:\n#                covid_max = curr_count\n#            curr_count = 0\n#            \n#print(\"The COVID set has a max sentence length of\", covid_max)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:17:47.660580Z","iopub.execute_input":"2022-05-12T11:17:47.661024Z","iopub.status.idle":"2022-05-12T11:17:48.848050Z","shell.execute_reply.started":"2022-05-12T11:17:47.660987Z","shell.execute_reply":"2022-05-12T11:17:48.847314Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"covid_tokens = tokenizer.batch_encode_plus(\n    list(split_covid_events['Event Tweets']),\n    add_special_tokens = False,\n    max_length = covid_max,\n    pad_to_max_length = True,\n    truncation = True\n)\n\ncovid_ids = torch.tensor(covid_tokens['input_ids'])\ncovid_mask = torch.tensor(covid_tokens['attention_mask'])\n\ncovid_data = TensorDataset(covid_ids, covid_mask)\ncovid_sampler = RandomSampler(covid_data)\ncovid_loader = DataLoader(covid_data, sampler = covid_sampler, batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:17:48.849493Z","iopub.execute_input":"2022-05-12T11:17:48.849727Z","iopub.status.idle":"2022-05-12T11:19:27.453659Z","shell.execute_reply.started":"2022-05-12T11:17:48.849694Z","shell.execute_reply":"2022-05-12T11:19:27.452895Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"# use f'best_weights.pt' if 'Task 1' was ran, if not used the initially saved best weights of our best model\n#weight_file = f'best_weights.pt'\nweight_file = '/kaggle/input/preprocessed-data/best_weights.pt'\nmodel.load_state_dict(torch.load(weight_file))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:19:27.455358Z","iopub.execute_input":"2022-05-12T11:19:27.455598Z","iopub.status.idle":"2022-05-12T11:19:31.365914Z","shell.execute_reply.started":"2022-05-12T11:19:27.455565Z","shell.execute_reply":"2022-05-12T11:19:31.365185Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"with torch.no_grad():\n    preds = model(covid_ids.to('cuda'), covid_mask.to('cuda'))\n    preds = preds.detach().cpu().numpy()\n    preds = np.argmax(preds, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:19:31.366999Z","iopub.execute_input":"2022-05-12T11:19:31.367231Z","iopub.status.idle":"2022-05-12T11:19:39.179246Z","shell.execute_reply.started":"2022-05-12T11:19:31.367197Z","shell.execute_reply":"2022-05-12T11:19:39.178508Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#with open('/kaggle/working/covid_preds_1.csv', 'w', newline='') as o:\nwith open('/kaggle/working/covid_preds_2.csv', 'w', newline='') as o:\n    csv_write = csv.writer(o)\n    csv_write.writerow(['Id', 'Predicted'])\n\n    for i in range(len(preds)):\n        idx = i\n        is_rumour = preds[i]\n        csv_write.writerow([idx, is_rumour])","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:21:50.202193Z","iopub.execute_input":"2022-05-12T11:21:50.202604Z","iopub.status.idle":"2022-05-12T11:21:50.225868Z","shell.execute_reply.started":"2022-05-12T11:21:50.202571Z","shell.execute_reply":"2022-05-12T11:21:50.225133Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}